<html>
    <head>
        <title>Detecting Emotion in Text: Chatbots in the Browser with TensorFlow.js</title>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder"></script>
    </head>
    <body>
        <p id="text"></p>
        <h1 id="status">Loading...</h1>
        <h1 id="loading_status"></h1>
        <textarea name="" id="user-text" cols="30" rows="10"></textarea>
        <p id="results"></p>
        <script src="model.js"></script>
        <script>
        const emotions = [
            "admiration",
            "amusement",
            "anger",
            "annoyance",
            "approval",
            "caring",
            "confusion",
            "curiosity",
            "desire",
            "disappointment",
            "disapproval",
            "disgust",
            "embarrassment",
            "excitement",
            "fear",
            "gratitude",
            "grief",
            "joy",
            "love",
            "nervousness",
            "optimism",
            "pride",
            "realization",
            "relief",
            "remorse",
            "sadness",
            "surprise",
            "neutral"
        ];

        function setText( text ) {
            document.getElementById( "status" ).innerText = text;
        }

        function shuffleArray( array ) {
            for( let i = array.length - 1; i > 0; i-- ) {
                const j = Math.floor( Math.random() * ( i + 1 ) );
                [ array[ i ], array[ j ] ] = [ array[ j ], array[ i ] ];
            }
        }

        (async () => {
            // Load GoEmotions data (https://github.com/google-research/google-research/tree/master/goemotions)
            let data = await fetch( "web/emotions.tsv" ).then( r => r.text() );
            let lines = data.split( "\n" ).filter( x => !!x ); // Split & remove empty lines

            // Randomize the lines
            shuffleArray( lines );

            const numSamples = 200;
            let sentences = lines.slice( 0, numSamples ).map( line => {
                let sentence = line.split( "\t" )[ 0 ];
                return sentence;
            });
            let outputs = lines.slice( 0, numSamples ).map( line => {
                let categories = line.split( "\t" )[ 1 ].split( "," ).map( x => parseInt( x ) );
                let output = [];
                for( let i = 0; i < emotions.length; i++ ) {
                    output.push( categories.includes( i ) ? 1 : 0 );
                }
                return output;
            });

            // Load the universal sentence encoder
            setText( "Loading USE..." );
            let encoder = await use.load();
            setText( "Loaded!" );
            let embeddings = await encoder.embed( sentences );

            // Define our model with several hidden layers
            const model = tf.sequential();
            model.add(tf.layers.dense( { units: 100, activation: "relu", inputShape: [ 512 ] } ) );
            model.add(tf.layers.dense( { units: 50, activation: "relu" } ) );
            model.add(tf.layers.dense( { units: 25, activation: "relu" } ) );
            model.add(tf.layers.dense( {
                units: emotions.length,
                activation: "softmax"
            } ) );

            model.compile({
                optimizer: tf.train.adam(),
                loss: "categoricalCrossentropy",
                metrics: [ "accuracy" ]
            });

            const xs = embeddings;
            const ys = tf.stack( outputs.map( x => tf.tensor1d( x ) ) );
            await model.fit( xs, ys, {
                epochs: 50,
                shuffle: true,
                callbacks: {
                    onEpochEnd: ( epoch, logs ) => {
                        setText( `Training... Epoch #${epoch} (${logs.acc})` );
                        console.log( "Epoch #", epoch, logs );
                    }
                }
            } );
            const saveResult = await model.save('downloads://my-model-1');
            const model = await tf.loadLayersModel('./my-model.json')
            const loadingStatus = document.getElementById('loading_status');

            async function analyseText(){
                loadingStatus.innerText = "Loading....";


                let text = document.getElementById('user-text').value;

                document.getElementById( "text" ).innerText = text;

                let vector = await encoder.embed( [ text ] );
                let prediction = await model.predict( vector ).data();
                console.log(prediction[0].toFixed(2))
                console.log({prediction})
                
                // Get the index of the highest value in the prediction
                let id = prediction.indexOf( Math.max( ...prediction ) );

                let predictions = emotions.map((emotion,i) => {
                    console.log(i, "->", emotion, "=>", prediction[i]);
                    return{
                        category: emotion,
                        // value: prediction[i].toFixed(0) || 0
                    }
                    })
                    .sort((a, b) => b.value - a.value);

                    document.querySelector('#results').innerText = JSON.stringify(predictions, null, 2)
                    console.log({predictions})


                setText( `Result: ${emotions[ id ]}` );

                loadingStatus.innerText = "";
            }

            analyseText()
            document.addEventListener('keyup', async () => analyseText());


            // Test prediction every 5s
            setInterval( async () => {
                // Pick random text
                let line = lines[ Math.floor( Math.random() * lines.length ) ];
                let sentence = line.split( "\t" )[ 0 ];
                // console.log({sentence})
                // let categories = line.split( "\t" )[ 1 ].split( "," ).map( x => parseInt( x ) );
                document.getElementById( "text" ).innerText = sentence;

                let vector = await encoder.embed( [ sentence ] );
                let prediction = await model.predict( vector ).data();

                let predictions = emotions.map((emotion,i) => {
                    console.log(i, "->", emotion, "=>", prediction[i]);
                    return{
                        category: emotion,
                        // value: prediction[i].toFixed(0) || 0
                    }
                    })
                    .sort((a, b) => b.value - a.value);

                // Get the index of the highest value in the prediction
                let id = prediction.indexOf( Math.max( ...prediction ) );
                setText( `Result: ${emotions[ id ]}}` );
            }, 5000 );
        })();
        </script>
    </body>
</html>